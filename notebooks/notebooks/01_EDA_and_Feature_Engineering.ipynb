{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4f3f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8a7d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Load the cleaned and feature-engineered dataset\n",
    "\n",
    "# Define the path relative to the notebooks/ directory\n",
    "INPUT_FILE = '../data/processed/car_insurance_claim_clean.csv'\n",
    "data = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst 5 rows of the clean data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a505922",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Visualize the target variable ('Response') to confirm class imbalance\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(x='Response', data=data)\n",
    "plt.title('Distribution of the Target Variable (Response)')\n",
    "plt.xticks([0, 1], ['Did Not Buy (0)', 'Bought (1)'])\n",
    "plt.ylabel('Customer Count')\n",
    "plt.xlabel('Car Insurance Purchase')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the proportion of the positive class (Response=1)\n",
    "response_rate = data['Response'].mean()\n",
    "print(f\"Proportion of positive responses (Response=1): {response_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568964b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Categorical Encoding (One-Hot Encoding)\n",
    "\n",
    "# List of categorical columns to encode, including the new 'Mileage_Category'\n",
    "categorical_cols = [\n",
    "    'age', 'gender', 'race', 'driving_experience', \n",
    "    'education', 'income', 'vehicle_year', 'vehicle_type', \n",
    "    'Mileage_Category'\n",
    "]\n",
    "\n",
    "# Drop irrelevant unique identifier columns ('id', 'postal_code')\n",
    "data_to_encode = data.drop(columns=['id', 'postal_code'])\n",
    "\n",
    "# Perform One-Hot Encoding. drop_first=True to avoid multicollinearity.\n",
    "data_encoded = pd.get_dummies(data_to_encode, columns=categorical_cols, drop_first=True) \n",
    "\n",
    "print(f\"Data shape after One-Hot Encoding: {data_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587c5a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Define X (features) and y (target) and split data\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data_encoded.drop('Response', axis=1)\n",
    "y = data_encoded['Response']\n",
    "\n",
    "# Split data (70% Train for modeling, 30% Test for evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set size: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73fcf2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Fit Logistic Regression Model 1 (Key Factors)\n",
    "\n",
    "# Define the predictors for the model based on the initial hypothesis\n",
    "predictors = [\n",
    "    'age_26-39', 'age_40-64', 'age_65+',\n",
    "    'gender_male',\n",
    "    'past_accidents', \n",
    "    'vehicle_ownership',\n",
    "    'Mileage_Category_Střední_Nájezd', 'Mileage_Category_Vysoký_Nájezd',\n",
    "    'Credit_to_Mileage_Ratio'\n",
    "]\n",
    "\n",
    "# Ensure all selected predictors exist in the training data after encoding\n",
    "final_predictors = [p for p in predictors if p in X_train.columns]\n",
    "\n",
    "# Add Constant (Intercept) for statsmodels\n",
    "X_train_model1 = sm.add_constant(X_train[final_predictors])\n",
    "\n",
    "# Fit the Logit Model\n",
    "logit_model1 = sm.Logit(y_train, X_train_model1)\n",
    "# disp=False suppresses the iteration output during fitting\n",
    "result1 = logit_model1.fit(disp=False) \n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262d415",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Print Model Summary to evaluate significance (P-values) and coefficients\n",
    "\n",
    "print(\"Logistic Regression: Model 1 Results (Key Factors)\\n\" + \"=\"*60)\n",
    "print(result1.summary())\n",
    "\n",
    "# Interpretation Helper: Odds Ratios (e^coef)\n",
    "print(\"\\nOdds Ratios (Interpretation of change in odds for Response=1):\")\n",
    "print(np.exp(result1.params).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c6aeb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Model Evaluation on the Test Set\n",
    "\n",
    "# 1. Prediction on the test set\n",
    "X_test_model1 = sm.add_constant(X_test[final_predictors], has_constant='add')\n",
    "predictions_prob = result1.predict(X_test_model1)\n",
    "predictions_class = (predictions_prob >= 0.5).astype(int) # Standard threshold of 0.5\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions_class)\n",
    "print(\"\\nConfusion Matrix (Threshold 0.5):\")\n",
    "# [ [TN, FP], [FN, TP] ]\n",
    "print(conf_matrix)\n",
    "\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# 3. Calculate Key Metrics\n",
    "accuracy = accuracy_score(y_test, predictions_class)\n",
    "recall = recall_score(y_test, predictions_class)\n",
    "specificity = TN / (TN + FP)\n",
    "f1 = f1_score(y_test, predictions_class)\n",
    "\n",
    "print(f\"\\nClassification Metrics:\")\n",
    "print(f\"Accuracy (Overall Correctness): {accuracy:.4f}\")\n",
    "print(f\"Recall (Sensitivity - True Positive Rate): {recall:.4f}\")\n",
    "print(f\"Specificity (True Negative Rate): {specificity:.4f}\")\n",
    "print(f\"F1-Score (Harmonic Mean of Precision and Recall): {f1:.4f}\")\n",
    "\n",
    "# Final Note: Explain why Recall is important due to the class imbalance.\n",
    "print(\"\\nNote on Recall: Since the 'Did Not Buy' class (0) heavily outweighs the 'Bought' class (1), high Accuracy can be misleading. Recall is critical because it measures the model's ability to capture the actual positive customers (True Buyers), minimizing missed business opportunities (False Negatives).\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
